# LaughGraph: Serious + Human-Fun AI Research Digest

![Python](https://img.shields.io/badge/python-3.8+-blue.svg)
![LangGraph](https://img.shields.io/badge/LangGraph-powered-green.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

> Making AI research papers both educational and fun â€” because who says science can't make you smile? ğŸ˜Š

## ğŸ¯ Core Purpose

To help researchers, students, and curious readers understand AI research papers quickly â€” with clear explanations and light, witty humor that makes the insights stick.

## ğŸš€ The Problem

AI research papers are often:
- Dense and difficult to understand
- Repetitive with similar approaches
- Over-hyped with minimal actual novelty
- Boring for general audiences

Readers either struggle to understand them or get bored halfway through.

## ğŸ’¡ The Solution

A **LangGraph-powered assistant** that produces two synchronized perspectives for each paper:

- **Serious summary** â†’ accurate, structured explanation
- **Human-fun version** â†’ light humor, analogies, and emojis that make it relatable

## ğŸ”— Why LangGraph?

- **Branching**: Supports serious vs fun processing paths
- **Conditions**: If novelty is low â†’ add playful "same recipe" analogies
- **Feedback loops**: Fun side can ask serious side for clarity
- **Workflow orchestration**: Complex multi-step processing with decision points

## ğŸ§© Workflow Nodes

```mermaid
graph TD
    A[Ingestion] --> B[Summarizer]
    B --> C[Contextualizer]
    B --> D[Novelty Analyzer]
    C --> E[Human-Fun Node]
    D --> E
    E --> F[Synthesis]
    F --> G[Output]
```

### Node Details:

1. **Ingestion** â†’ Fetch & parse papers (arXiv, PDFs)
2. **Summarizer** â†’ Generate plain-language + technical summaries
3. **Contextualizer** â†’ Explain how the paper fits in the field
4. **Novelty Analyzer** â†’ Rate how new the idea actually is
5. **Human-Fun Node** â†’ Add friendly humor:
   - "Impressive engineering!" ğŸ”§
   - Light jokes about computational effort (e.g., "GPUs working overtime")
   - Analogies (e.g., "bigger pizza ğŸ• = better model")
6. **Synthesis** â†’ Merge serious + fun into one cohesive digest
7. **Output** â†’ Generate blog posts, markdown, tweet threads, or meme-ready captions

## ğŸŒŸ Key Features

- **Dual Perspective**: "What the paper says" + "How it feels in human language"
- **Gentle Humor**: No harsh roasts â€” just witty analogies and light jokes
- **Conditional Fun**: Humor depth adapts (low novelty â†’ more playful analogies)
- **Trend Tracking**: Identifies repeated themes ("yet another fine-tune") 
- **Accessible Digest**: Makes research both educational and entertaining

## ğŸ†š What's Unique?

Other tools either:
- Summarize papers seriously (boring) ğŸ“š
- Make jokes without structure (unhelpful) ğŸƒ

**LaughGraph** = Structured research analysis + human-fun commentary in one conditional workflow.

> Think of it as a study guide that explains papers clearly while also making you smile! ğŸ˜„

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8+
- uv (recommended) or pip

### Setup

```bash
# Clone the repository
git clone https://github.com/yourusername/laughgraph.git
cd laughgraph

# Install dependencies with uv
uv sync

# Or with pip
pip install -r requirements.txt

# Set up environment variables
cp .env.example .env
# Edit .env with your API keys (OpenAI, ArXiv, etc.)
```

### Environment Variables

```bash
OPENAI_API_KEY=your_openai_key
ARXIV_API_BASE=http://export.arxiv.org/api/query
CHROMA_PERSIST_DIR=./db/chroma_store
```

## ğŸš€ Quick Start

```python
from arxiv_docs import ArxivAPI
from langraph_pipeline import LaughGraphPipeline

# Initialize the pipeline
pipeline = LaughGraphPipeline()

# Process a paper from ArXiv ID
result = pipeline.process_paper("2312.12345")

print("Serious Summary:")
print(result.serious_summary)

print("\nFun Version:")
print(result.fun_summary)
```

## ğŸ“ Project Structure

```
paper_sum/
â”œâ”€â”€ arxiv_docs/           # ArXiv API and PDF processing
â”‚   â”œâ”€â”€ arxiv_api.py     # Fetch papers from ArXiv
â”‚   â””â”€â”€ clean_pdfs.py    # PDF parsing and chunking
â”œâ”€â”€ db/                  # Vector database storage
â”‚   â””â”€â”€ chroma_store/    # Chroma embeddings
â”œâ”€â”€ research_papers/     # Downloaded PDFs and extracted text
â”œâ”€â”€ langraph_nodes/      # LangGraph workflow nodes
â”œâ”€â”€ main.py             # Main application entry point
â”œâ”€â”€ pyproject.toml      # Project dependencies
â””â”€â”€ README.md           # This file
```

## ğŸ”„ Workflow Examples

### Processing Pipeline

1. **Input**: ArXiv paper ID or PDF file
2. **Extraction**: Parse content and create chunks
3. **Analysis**: Generate serious technical summary
4. **Fun Generation**: Add humor and analogies
5. **Output**: Combined digest with both perspectives

### Sample Output

**Paper**: "Attention Is All You Need"

**Serious**: "The paper introduces the Transformer architecture, replacing recurrent layers with self-attention mechanisms for sequence-to-sequence tasks..."

**Fun**: "The authors basically said 'Who needs memory when you have really good focus?' and created a model that pays attention to everything at once. It's like having ADHD but in a productive way! ğŸ§ âœ¨"

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup

```bash
# Install development dependencies
uv sync --dev

# Run tests
pytest

# Format code
black .
isort .

# Type checking
mypy .
```

## ğŸ“Š Roadmap

- [ ] **v1.0**: Basic ArXiv processing with dual summaries
- [ ] **v1.1**: Web interface for interactive paper exploration
- [ ] **v1.2**: Social media thread generation
- [ ] **v2.0**: Multi-language support
- [ ] **v2.1**: Audio summaries with different tones
- [ ] **v3.0**: Real-time paper trend analysis

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **LangGraph** team for the amazing workflow framework
- **ArXiv** for providing open access to research papers
- **Chroma** for vector database capabilities
- The research community for creating papers worth summarizing (and gently joking about)

## ğŸ“ Contact

- **Issues**: [GitHub Issues](https://github.com/yourusername/laughgraph/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/laughgraph/discussions)
- **Email**: your.email@example.com

---

*"Making AI research accessible, one laugh at a time!"* ğŸ˜„ğŸ”¬
